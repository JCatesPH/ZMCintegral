{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Coded by ZHANG Junjie (University of Science and Technology of China) in 10/2018.\n",
    "\n",
    "This program is free: you can redistribute it and/or modify it under the terms of \n",
    "the Apache License Version 2.0, January 2004 (http://www.apache.org/licenses/).\n",
    "\n",
    "The program requires python tensorflow and numpy to be pre-installed in your \n",
    "GPU-supported computer. \n",
    "\n",
    "'''\n",
    "ZMCIntegral_VERSION = '2.2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.eager.context import context, EAGER_MODE, GRAPH_MODE\n",
    "import os,sys\n",
    "import math\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "        \n",
    "# detect if GPU is available on the computer\n",
    "def is_gpu_available(cuda_only = True):\n",
    "    \n",
    "    from tensorflow.python.client import device_lib as _device_lib\n",
    "    \n",
    "    if cuda_only:\n",
    "        gpu_available=[int(x.name[-1]) for x in _device_lib.list_local_devices() if (x.device_type == 'GPU')]\n",
    "        np.save(os.getcwd()+'/multi_temp/gpu_available', gpu_available)\n",
    "    else:\n",
    "        gpu_available=[int(x.name[-1]) for x in _device_lib.list_local_devices() if (x.device_type == 'GPU' or x.device_type == 'SYCL')]\n",
    "        np.save(os.getcwd()+'/multi_temp/gpu_available', gpu_available)\n",
    "        \n",
    "\n",
    "\n",
    "class MCintegral():\n",
    "    \n",
    "    def __init__(self, my_func = None, domain = None, available_GPU = None, num_trials = 5, depth = None, sigma_multiplication = 4,method=None):\n",
    "\n",
    "        '''\n",
    "        Parameters:\n",
    "            my_func: user defined multidimensional function, type:function\n",
    "            domain: integration domain, type:list/numpy_array, eg [[0,1]] or [[0,1],[0,1]]\n",
    "            available_GPU: list of available gpus, type: list, Default: All GPUs detected, eg [0,1,2,3]\n",
    "            num_trial: number of trials, type:int, Default:5\n",
    "            depth: search depth, type:int, Default:2\n",
    "            sigma_multiplication: recalculate the grid if `stddev` larger than `sigma_mean + sigma_multiplication * sigma`, type:float, Default:4\n",
    "        '''\n",
    "        \n",
    "        # choose eager mode\n",
    "        def switch_to(mode):\n",
    "            ctx = context()._eager_context\n",
    "            ctx.mode = mode\n",
    "            ctx.is_eager = (mode == EAGER_MODE)\n",
    "        # set to eager mode\n",
    "        switch_to(EAGER_MODE)\n",
    "        assert tf.executing_eagerly()\n",
    "        \n",
    "        # clean temp file\n",
    "        self.clean_temp()\n",
    "        \n",
    "        if available_GPU == None:\n",
    "            # check gpu condition\n",
    "            p = multiprocessing.Process(target = is_gpu_available)\n",
    "            p.daemon = True\n",
    "            p.start()\n",
    "            p.join()\n",
    "            \n",
    "            available_GPU = np.load(os.getcwd() + '/multi_temp/gpu_available.npy')\n",
    "        \n",
    "        if len(available_GPU) == 0:\n",
    "            raise AssertionError(\"Your computer does not support GPU calculation.\")\n",
    "            \n",
    "        if method == None or method == 'AdaptiveImportanceMC':\n",
    "        \n",
    "            # number of trials\n",
    "            self.num_trials = num_trials\n",
    "            \n",
    "            # depth of the zooming search\n",
    "            if depth==None:\n",
    "                self.depth = 2\n",
    "            else:\n",
    "                self.depth = depth\n",
    "             \n",
    "            self.method = 'AdaptiveImportanceMC'\n",
    "        \n",
    "        if method == 'AverageDigging':\n",
    "        \n",
    "            # number of trials\n",
    "            self.num_trials = 1\n",
    "            \n",
    "            # depth of the zooming search\n",
    "            if depth==None:\n",
    "                self.depth = 1\n",
    "            else:\n",
    "                self.depth = depth\n",
    "                \n",
    "            self.method='AverageDigging'\n",
    "        \n",
    "        \n",
    "        # recalculate the grid if `stddev` larger than `sigma_mean + sigma_multiplication * sigma`\n",
    "        self.sigma_multiplication = sigma_multiplication\n",
    "           \n",
    "        # set up initial conditions\n",
    "        self.available_GPU = available_GPU\n",
    "\n",
    "        # initialize the preparing integrated function depend on its domain dimension\n",
    "        self.initial(my_func, domain)\n",
    "        \n",
    "        # initial domain\n",
    "        self.initial_domain = domain\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.configure_chunks()\n",
    "        MCresult = self.importance_sampling_iteration(self.initial_domain, 0)\n",
    "        \n",
    "        return MCresult\n",
    "    \n",
    "    def importance_sampling_iteration(self, domain, depth):\n",
    "        depth += 1\n",
    "        MCresult_chunks, large_std_chunk_id, MCresult_std_chunks = self.MCevaluate(domain)\n",
    "        if depth < self.depth:\n",
    "            for chunk_id in large_std_chunk_id:\n",
    "                # domain of this chunk\n",
    "                domain_next_level = self.chunk_domian(chunk_id, domain)\n",
    "                # iteration\n",
    "                MCresult_chunks[chunk_id],MCresult_std_chunks[chunk_id] = self.importance_sampling_iteration(domain_next_level, depth)\n",
    "        \n",
    "        # Stop digging if there are no more large stddev chunk\n",
    "        if len(large_std_chunk_id) == 0:\n",
    "            return np.sum(MCresult_chunks,0), np.sqrt(np.mean(MCresult_std_chunks**2,0))\n",
    "\n",
    "        return np.sum(MCresult_chunks,0), np.sqrt(np.mean(MCresult_std_chunks**2,0))\n",
    "    \n",
    "    def MCevaluate(self, domain):\n",
    "\n",
    "        '''\n",
    "        Monte Carlo integration.\n",
    "        Parameters:\n",
    "            domain: the integration domain, type:list or numpy_array.\n",
    "        '''\n",
    "        \n",
    "        p={}\n",
    "        for i_batch in range(self.n_batches):\n",
    "            def multi_processing():\n",
    "                os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "                os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(i_batch)\n",
    "                result = []\n",
    "                for trial in range(self.num_trials):\n",
    "                    result.append(self.MCkernel(domain, i_batch))\n",
    "                result = np.array(result)\n",
    "                std_result = np.std(result,0)\n",
    "                mean_result = np.mean(result,0)\n",
    "                np.save(os.getcwd()+'/multi_temp/result'+str(i_batch), np.array(mean_result))\n",
    "                np.save(os.getcwd()+'/multi_temp/result_std'+str(i_batch), np.array(std_result))\n",
    "                \n",
    "            # start multi-processing to allocate     \n",
    "            p[i_batch] = multiprocessing.Process(target = multi_processing)\n",
    "            p[i_batch].daemon = True\n",
    "            p[i_batch].start()\n",
    "            \n",
    "        for i_batch in range(self.n_batches):   \n",
    "            p[i_batch].join()\n",
    "                \n",
    "        MCresult = []\n",
    "        MCresult_std = []\n",
    "        for i_batch in range(self.n_batches): \n",
    "            MCresult.append(np.load(os.getcwd()+'/multi_temp/result'+str(i_batch)+'.npy'))\n",
    "            MCresult_std.append(np.load(os.getcwd()+'/multi_temp/result_std'+str(i_batch)+'.npy'))\n",
    "        \n",
    "        MCresult, MCresult_std = np.concatenate(MCresult), np.concatenate(MCresult_std)\n",
    "        \n",
    "        # find out the index of chunks that have very large stddev\n",
    "        if len(np.shape(MCresult))==1:\n",
    "            threshold = np.mean(MCresult_std) + self.sigma_multiplication * np.std(MCresult_std)\n",
    "            large_std_chunk_id = np.where(MCresult_std >= threshold)[0]\n",
    "            return MCresult, large_std_chunk_id, MCresult_std\n",
    "        else:\n",
    "            MCresult_std = np.transpose(MCresult_std)\n",
    "            threshold = np.mean(MCresult_std,-1) + self.sigma_multiplication * np.std(MCresult_std,-1)\n",
    "            large_std_chunk_id = np.unique(np.concatenate([np.where(MCresult_std[i] >= threshold[i])[0] for i in range(len(MCresult_std))]))\n",
    "            return MCresult, large_std_chunk_id, np.transpose(MCresult_std)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def initial(self, my_func, domain):\n",
    "        '''\n",
    "        To obtain proper initial conditions:\n",
    "            self.dim: number of free variables, type:int,\n",
    "            self.chunk_size: number of samplings in each chunk, type:int\n",
    "            self.n_grid: total number of d-dimensional samplings, type:int\n",
    "            self.n_batches: seperate data into n_batches parts, type:int\n",
    "        Parameters:\n",
    "            my_func: user defined multidimensional function, type:function\n",
    "            domain: integration domain, type:list/numpy_array, eg [[0,1]] or [[0,1],[0,1]]\n",
    "        '''    \n",
    "\n",
    "        # detect if enter a function             \n",
    "        if my_func == None:\n",
    "            raise AssertionError(\"Invalid input function\")\n",
    "        # the preparing integrated function\n",
    "        self.my_func = my_func\n",
    "\n",
    "        # detect if domain is in right form\n",
    "        if domain == None:\n",
    "            raise AssertionError(\"Please enter a domain\")\n",
    "        for temp in domain:\n",
    "            if len(temp) != 2:\n",
    "                raise AssertionError(\"Domain is incorrect\")\n",
    "            if temp[1] < temp[0]:\n",
    "                raise AssertionError(\"Domain [a,b] should satisfy b>a\")\n",
    "                \n",
    "        # integrating dimension\n",
    "        self.dim = len(domain)\n",
    "        \n",
    "        # get `total sampling number` and `sampling number in one chunk` depend on dimension of integral       \n",
    "        if self.dim == 1:\n",
    "            self.chunk_size_x = 65536\n",
    "            \n",
    "        elif self.dim == 2:\n",
    "            self.chunk_size_x = 4096\n",
    "            \n",
    "        elif self.dim == 3:\n",
    "            self.chunk_size_x = 256\n",
    "\n",
    "        elif self.dim == 4:\n",
    "            self.chunk_size_x = 64\n",
    "            \n",
    "        elif self.dim == 5:\n",
    "            self.chunk_size_x = 24\n",
    "            \n",
    "        elif self.dim == 6:\n",
    "            self.chunk_size_x = 10\n",
    "            \n",
    "        elif self.dim == 7:\n",
    "            self.chunk_size_x = 8\n",
    "            \n",
    "        elif self.dim == 8:\n",
    "            self.chunk_size_x = 6\n",
    "            \n",
    "        elif self.dim == 9:\n",
    "            self.chunk_size_x = 5\n",
    "            \n",
    "        elif self.dim == 10:\n",
    "            self.chunk_size_x = 4\n",
    "            \n",
    "        elif self.dim == 11:\n",
    "            self.chunk_size_x = 3\n",
    "            \n",
    "        else:\n",
    "            self.chunk_size_x = 2\n",
    "        \n",
    "        self.chunk_size_multiplier = int(math.floor((len(self.available_GPU)*192)**(1/self.dim)))\n",
    "        \n",
    "    def configure_chunks(self):\n",
    "        '''receieve self.dim, self.n_grid and self.chunk_size'''\n",
    "        \n",
    "        '''\n",
    "            below, `int(np.round())` can make sure you got the exact number, \n",
    "            eg: in Python, you may get 7.99999 from 64^(1/2)\n",
    "        '''\n",
    "        \n",
    "        self.chunk_size = self.chunk_size_x**self.dim\n",
    "        self.n_grid = (self.chunk_size_x*self.chunk_size_multiplier)**self.dim\n",
    "        \n",
    "        # number of samplings in one chunk along one dimension\n",
    "        self.n_grid_x_one_chunk = int(np.round(self.chunk_size**(1/self.dim)))\n",
    "        \n",
    "        # number of chunks\n",
    "        self.n_chunk = int(np.round(self.n_grid/self.chunk_size))\n",
    "        \n",
    "        # number of samplings along one dimension\n",
    "        self.n_grid_x = int(np.round(self.n_grid**(1/self.dim)))\n",
    "        \n",
    "        # number of chunks along one dimension\n",
    "        self.n_chunk_x = int(np.round(self.n_chunk**(1/self.dim)))\n",
    "        \n",
    "        # number of batches\n",
    "        self.n_batches = min([len(self.available_GPU), self.n_chunk])\n",
    "        \n",
    "        # batch_size\n",
    "        self.batch_size = int(np.ceil(self.n_chunk/self.n_batches))\n",
    "\n",
    "    def clean_temp(self):\n",
    "        folder = os.getcwd()+'/multi_temp/'\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            \n",
    "        # clean temp file\n",
    "        for the_file in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, the_file)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "                \n",
    "    def chunk_domian(self, chunk_id, original_domain):\n",
    "\n",
    "        '''\n",
    "        Return:\n",
    "            domain of integration in this chunk.\n",
    "        Parameters:\n",
    "            chunk_id: current chunk id, type:int.\n",
    "            original_domain: the domain of the previous original integration.\n",
    "        '''\n",
    "\n",
    "        chunk_id_d_dim = self.convert_1d_to_nd(chunk_id, self.dim, self.n_chunk_x)\n",
    "        domain_range = np.array([(original_domain[idim][1] - original_domain[idim][0]) / self.n_chunk_x for idim in range(self.dim)], dtype=np.float32)\n",
    "        domain_left = np.array([original_domain[idim][0] + chunk_id_d_dim[idim] * domain_range[idim] for idim in range(self.dim)], dtype=np.float32)\n",
    "        current_domain = [[domain_left[i], domain_left[i] + domain_range[i]] for i in range(self.dim)]\n",
    "        return current_domain\n",
    "    \n",
    "    def convert_1d_to_nd(self, one_d, dim, system_digit):\n",
    "\n",
    "        '''\n",
    "        Function:\n",
    "            convert `one_d` index to `n_d` index of arbitrary systems\n",
    "        Parameters:\n",
    "            one_d: current index in the whole 1 dimension sequence, type:int.\n",
    "            dim: the real system dimension, type:int.\n",
    "            system_digit: the length in one dimension of the real system, type:int.\n",
    "        '''\n",
    "\n",
    "        temp_point = np.zeros(dim)\n",
    "        for i_dim in range(dim):\n",
    "            temp_i_one_d = one_d\n",
    "            for temp_dim in range(dim):\n",
    "                temp_i_one_d -= temp_point[temp_dim] * (system_digit**(dim-temp_dim-1))\n",
    "            temp_point[i_dim] = math.floor(temp_i_one_d / (system_digit**(dim-i_dim-1)))\n",
    "        return temp_point\n",
    "    \n",
    "    def MCkernel(self, domain, i_batch):\n",
    "\n",
    "        '''\n",
    "        Function:\n",
    "            multiprocessing Monte Carlo integration on specific GPU\n",
    "        Parameters:\n",
    "            domain: domain of the integral, eg: [[a,b],[c,d],...].\n",
    "            i_batch: the index of current GPU, type:int.\n",
    "        '''\n",
    "\n",
    "        MCresult = []\n",
    "        for i_chunk in range(self.batch_size):\n",
    "            chunk_id = i_chunk + i_batch * self.batch_size\n",
    "            if chunk_id < self.n_chunk:\n",
    "                chunk_id_d_dim = self.convert_1d_to_nd(chunk_id, self.dim, self.n_chunk_x)\n",
    "             \n",
    "                domain_range = np.array([(domain[idim][1] - domain[idim][0]) / self.n_chunk_x for idim in range(self.dim)], dtype=np.float32)\n",
    "                domain_left = np.array([domain[idim][0] + chunk_id_d_dim[idim] * domain_range[idim] for idim in range(self.dim)], dtype=np.float32)\n",
    "                    \n",
    "                if self.method=='AdaptiveImportanceMC':\n",
    "                    # random variables of sampling points\n",
    "                    random_domain_values = [tf.random_uniform([self.chunk_size], minval=domain_left[i_dim],\\\n",
    "                                                          maxval=domain_left[i_dim]+domain_range[i_dim],dtype=tf.float32)\\\n",
    "                                            for i_dim in range(self.dim)]\n",
    "                \n",
    "                elif self.method=='AverageDigging':\n",
    "                    # sampling specified points\n",
    "                    domain_temp = [tf.range(start=0,limit=self.chunk_size_x,delta=1,dtype=tf.float32)/self.chunk_size_x*domain_range[i_dim]\\\n",
    "                                            +domain_left[i_dim]+domain_range[i_dim]*0.5/(self.chunk_size_x)\\\n",
    "                                            for i_dim in range(self.dim)]\n",
    "                    meshed_domain = tf.meshgrid(*domain_temp)\n",
    "                    random_domain_values = [tf.reshape(meshed_domain[i_dim],[self.chunk_size,]) for i_dim in range(self.dim)]\n",
    "                    \n",
    "                # user defined function, tensor calculation\n",
    "                user_func = self.my_func(random_domain_values)\n",
    "            \n",
    "                # suppress singularities into 0.0\n",
    "                user_func = tf.where(tf.is_nan(user_func), tf.zeros_like(user_func, dtype=tf.float32), user_func)\n",
    "                user_func = tf.where(tf.is_inf(user_func), tf.zeros_like(user_func, dtype=tf.float32), user_func)\n",
    "            \n",
    "                # monte carlo result in this small chunk\n",
    "                MCresult.append(tf.scalar_mul(np.prod(domain_range, dtype=np.float32), tf.reduce_mean(user_func, -1)).numpy())\n",
    "           \n",
    "        return np.array(MCresult) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
